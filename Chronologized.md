### 2024-12
* DiffusionDrive: Truncated Diffusion Model for End-to-End Autonomous Driving [[Note](papers/DiffusionDrive.md)] [CVPR]
* EMMA: End-to-End Multimodal Model for Autonomous Driving [[Note](papers/EMMA.md)]
* Hydra-MDP: End-to-end Multimodal Planning with Multi-target Hydra-Distillation [[Note](papers/Hydra-MDP.md)]
* Behavior Transformers: Cloning k modes with one stone [[Note](papers/behavior_transformers.md)]


### 2024-03
* HiVT: Hierarchical Vector Transformer for Multi-Agent Motion Prediction [[Note](papers/HiVT.md)] [CVPR 22](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_HiVT_Hierarchical_Vector_Transformer_for_Multi-Agent_Motion_Prediction_CVPR_2022_paper.pdf) `Motion Prediction` 
* Query-Centric Trajectory Prediction [[Note](papers/QCNet.md)] [CVPR 23](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhou_Query-Centric_Trajectory_Prediction_CVPR_2023_paper.pdf) `Motion Prediction` 
* QCNeXt: A Next-Generation Framework For Joint Multi-Agent Trajectory Prediction [[Note](papers/QCNeXt.md)] [arXiv 23](https://arxiv.org/pdf/2306.10508.pdf) `Motion Prediction` 

### 2024-02
* Motion Transformer with Global Intention Localization and Local Movement Refinement [[Note]()] [NeurIPS 22](https://arxiv.org/pdf/2209.13508.pdf) <kbd>Max Planck</kbd> `Motion Prediction` 
* MTR++: Multi-Agent Motion Prediction with Symmetric Scene Modeling and Guided Intention Querying [[Note]()] [PAMI 24](https://arxiv.org/pdf/2306.17770.pdf) <kbd>Max Planck</kbd> `Motion Prediction` 


### 2024-01
* VectorMapNet: End-to-end Vectorized HD Map Learning [[Note]()] [arXiv 23](https://arxiv.org/pdf/2206.08920.pdf) <kbd>MARS Lab</kbd> `Road Topology` 
* MapTR: Structured Modeling and Learning for Online Vectorized HD Map Construction
 [[Note]()] [ICLR 23](https://arxiv.org/pdf/2208.14437.pdf) <kbd>Horizon</kbd> `Road Topology`
* TopoNet: Graph-based Topology Reasoning for Driving Scenes [[Note]()] [arXiv 23](https://arxiv.org/pdf/2304.05277.pdf) <kbd>OpenDriveLab</kbd> `Road Topology`
* TopoMLP: An Simple yet Strong Pipeline for Driving Topology Reasoning [[Note]()] [ICLR 24](https://arxiv.org/pdf/2310.06753.pdf) `Road Topology`
* Large Trajectory Models are Scalable Motion Predictors and Planners [[Note]()] [arXiv 23](https://arxiv.org/pdf/2310.19620.pdf) `Planner Model`



### 2023-12
* A Survey on Multimodal Large Language Models for Autonomous Driving [[Note]()] [arXiv](https://arxiv.org/pdf/2311.12320.pdf)
* OpenLane-V2: A Topology Reasoning Benchmark for Unified 3D HD Mapping [[Note]()] [NerIPS 23](https://arxiv.org/pdf/2304.10440.pdf)


### 2022-01
* Perceiver: General Perception with Iterative Attention[[Note](papers/Perceiver.md)] <kbd>Deepmind</kbd>  `Transformer`
* Perceiver IO: A General Architecture for Structured Inputs & Outputs[[Note](papers/Perceiver.md)] <kbd>Deepmind</kbd>  `Transformer`



### 2021-01
* Visual Odometry Revisited: What Should Be Learnt?][[Note](papers/DF-VO.md)] <kbd>ICRA 20</kbd>  `VO`
* OneNet: Towards End-to-End One-Stage Object Detection][[Note](papers/OneNet.md)] <kbd>arXiv 20</kbd>  `OD`
* Sparse R-CNN: End-to-End Object Detection with Learnable Proposals][[Note](papers/SparseRCNN.md)] <kbd>arXiv 20</kbd>  `OD`
* End-to-End Object Detection with Fully Convolutional Network][[Note](papers/DeFCN.md)] <kbd>arXiv 20</kbd>  `OD`
* Rethinking Transformer-based Set Prediction for Object Detection][[Note]] <kbd>arXiv 20</kbd>  `Transformer`
* Toward Transformer-Based Object Detection][[Note]] <kbd>arXiv 20</kbd>  `Transformer`
* End-to-end Lane Shape Prediction with Transformers][[Note]] <kbd>arXiv 20</kbd>  `Transformer`
* DETR for Pedestrian Detection][[Note]] <kbd>arXiv 20</kbd>  `Transformer`
* End-to-End Video Instance Segmentation with Transformers][[Note]] <kbd>arXiv 20</kbd>  `Transformer`
* InfoFocus: 3D Object Detection for Autonomous Driving with Dynamic Information Modeling][[Note](papers/InfoFocus.md)] <kbd>ECCV 20</kbd>  `PC`
* BoxInst: High-Performance Instance Segmentation with Box Annotations][[Note]] <kbd>ArXiv 20</kbd>  `PC`


### 2020-11
* Center3D: Center-based Monocular 3D Object Detection with Joint Depth Understanding][[Note](papers/Center3D.md)] <kbd>arXiv 20</kbd>  `Mono3D`
* Center-based 3D Object Detection and Tracking][[Note](papers/centerpoint.md)] <kbd>CVPR 20</kbd>  `PC`
* 3DSSD: Point-based 3D Single Stage Object Detector][[Note](papers/3DSSD.md)] <kbd>CVPR 20</kbd>  `PC`
* PointRCNN: 3D Object Proposal Generation and Detection from Point Cloud][[Note](papers/PointRCNN.md)] <kbd>CVPR 19</kbd>  `PC`


### 2020-10
* SOLO: Segmenting Objects by Locations][[Note](papers/SOLO.md)] <kbd>ECCV 20</kbd>  `IS`
* SOLOv2: Dynamic, Faster and Stronger][[Note](papers/SOLO.md)] <kbd>NeurIPS 20</kbd>  `IS`
* YOLACT++: Better Real-time Instance Segmentation [[Note](papers/YOLACT.md)] <kbd>PAML 20</kbd>  `IS`
* YOLACT: Real-time Instance Segmentation [[Note](papers/YOLACT.md)] <kbd>ICCV 19</kbd>  `IS`
* Generalized Focal Loss: Learning Qualified and Distributed Bounding Boxes for Dense Object Detection [[Note](papers/GFocal.md)] <kbd>NeurIPS 20</kbd>  `OD`
* TIDE: A General Toolbox for Identifying Object Detection Errors [[Note](papers/tide.md)] <kbd>ECCV 20</kbd>  `OD`


### 2020-09
* SoDA: Multi-Object Tracking with Soft Data Association [[Note](papers/SoDA.md)] <kbd>arXiv 20</kbd>  `MOT`
* Hidden Technical Debt in Machine Learning Systems [[Note](papers/MLStack.md)] <kbd>NeurIPS 15</kbd>  `Production`
* The ML Test Score: A Rubric for ML Production Readiness and Technical Debt Reduction [[Note](papers/MLStack.md)] <kbd>IEEE BigData 17</kbd>  `Production`


### 2020-08
* Object Detection as a Machine Learning Problem [[Note](lectures/rethink_OD_girshick.md)] <kbd>ECCVW 20</kbd>  `OD`
* FCOS: Fully Convolutional One-Stage Object Detection [[Note](papers/FCOS.md)] <kbd>ICCV 19</kbd>  `OD`
* Bridging the Gap Between Anchor-based and Anchor-free Detection via Adaptive Training Sample Selection [[Note](papers/ATSS.md)] <kbd>CVPR 20</kbd>  `OD`
* A Simple Baseline for Multi-Object Tracking [[Note](papers/FairMOT.md)] <kbd>ECCV 20?</kbd>  `MOT`
* Data Distillation: Towards Omni-Supervised Learning [[Note](papers/DataDistillationFAIR.md)] <kbd>CVPR 18</kbd>  `Semi-supervised`
* RetinaTrack: Online Single Stage Joint Detection and Tracking [[Note](papers/RetinaTrack.md)] <kbd>CVPR 20</kbd>  `MOT`


### 2020-07
* How To Train Your Deep Multi-Object Tracker [[Note](papers/DeepMOT.md)] <kbd>CVPR 20</kbd>  `MOT`
* Tracking Objects as Points [[Note](papers/CenterTrack.md)] <kbd>ECCV 20?</kbd>  `MOT`
* CrowdHuman: A Benchmark for Detecting Human in a Crowd [[Note](papers/CrowdHuman.md)] <kbd>ArXiv 18</kbd>  `Pedestrian`
* Simple Online and Realtime Tracking with a Deep Association Metric [[Note](papers/sort.md)] <kbd>ICIP 17</kbd>  `MOT`
* Towards Real-Time Multi-Object Tracking [[Note](papers/Towards-Realtime-MOT.md)] <kbd>ECCV 20?</kbd>  `MOT`
* GNN3DMOT: Graph Neural Network for 3D Multi-Object Tracking with Multi-Feature Learning [[Note](papers/GNN3DMOT.md)] <kbd>CVPR 20</kbd>  `MOT`
* SQE: a Self Quality Evaluation Metric for Parameters Optimization in Multi-Object Tracking [[Note](papers/SQE.md)] <kbd>CVPR 20</kbd>  `MOT`
* In Defense of the Classification Loss for Person Re-Identification [[Note](papers/cls-reid.md)] <kbd>CVPR 19</kbd>  `Pedestrian`


### 2020-06

* Self-Training With Noisy Student Improves ImageNet Classification [[Note](papers/noisestudent.md)] <kbd>CVPR 20</kbd>  `Semi-supervised`
* Itâ€™s Not All About Size: On the Role of Data Properties in Pedestrian Detection [[Note](papers/Its_Not_All_About_Size_On_the_Role_of_Data.md)] <kbd>ECCVW 18</kbd>  `Pedestrian`
* MonoLoco: Monocular 3D Pedestrian Localization and Uncertainty Estimation [[Note](papers/Monoloco.md)] <kbd>ICCV 19</kbd>  `Pedestrian`
* MEBOW: Monocular Estimation of Body Orientation In the Wild [[Note](papers/MEBOW.md)] <kbd>CVPR 20</kbd>  `Pedestrian`



<br/> 

### before 2020-06 (more casual, less organized)

* MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications  [[Paper](https://arxiv.org/abs/1704.04861)] [[Note](https://github.com/xudong19/DeepLearningNotes/blob/master/papers/MobileNets_series.md#mobilenets-efficient-convolutional-neural-networks-for-mobile-vision-applications)]
* MobileNetV2: Inverted Residuals and Linear Bottlenecks  [[Paper](https://arxiv.org/abs/1801.04381)] [[Note](https://github.com/xudong19/DeepLearningNotes/blob/master/papers/MobileNets_series.md#mobilenetv2-inverted-residuals-and-linear-bottlenecks)]
* Searching for MobileNetV3  [[Paper](https://arxiv.org/abs/1905.02244)] [[Note](https://github.com/xudong19/DeepLearningNotes/blob/master/papers/MobileNets_series.md#searching-for-mobilenetv3)]
* SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB model size  [[Paper](https://arxiv.org/abs/1602.07360)] [[Note](https://github.com/xudong19/DeepLearningNotes/blob/master/papers/squeezenet.md)]
* NetAdapt: Platform-Aware Neural Network Adaptation for Mobile Applications  [[Paper](https://arxiv.org/abs/1804.03230)] [[Note](https://github.com/xudong19/DeepLearningNotes/blob/master/papers/NetAdapt.md)]
* MnasNet: Platform-Aware Neural Architecture Search for Mobile  [[Paper](https://arxiv.org/abs/1807.11626)] [[Note](https://github.com/xudong19/DeepLearningNotes/blob/master/papers/MnasNet.md)]
* EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks  [[Paper](https://arxiv.org/abs/1905.11946)] [[Note](https://github.com/xudong19/DeepLearningNotes/blob/master/papers/EfficientNet.md)]
* Exploiting Kernel Sparsity and Entropy for Interpretable CNN Compression  [[Paper](https://arxiv.org/abs/1812.04368)] [[Note](https://github.com/xudong19/DeepLearningNotes/blob/master/papers/KSE.md)]
* LeGR: Filter Pruning via Learned Global Ranking  [[Paper](https://arxiv.org/abs/1904.12368)] [[Note](./papers/LeGR.md)]
* An Attention-based Recurrent Convolutional Network for Vehicle Taillight Recognition  [[Paper](https://arxiv.org/abs/1906.03683)] [[Note](https://github.com/xudong19/DeepLearningNotes/blob/master/papers/AttenRCN.md)] <kbd>IV19</kbd>
* DeepSignals: Predicting Intent of Drivers Through Visual Signals  [[Paper](https://arxiv.org/abs/1905.01333)] [[Note](https://github.com/xudong19/DeepLearningNotes/blob/master/papers/DeepSignals.md)] <kbd>ICRA19</kbd>
* VideoLSTM Convolves, Attends and Flows for Action Recognition  [[Paper](https://www.sciencedirect.com/science/article/pii/S1077314217301741)] [[Note](https://github.com/xudong19/DeepLearningNotes/blob/master/papers/VideoLSTM.md)] <kbd>CVIU18</kbd>
* Automotive Radar Dataset for Deep Learning Based 3D Object Detection  [[Paper](https://www.astyx.com/fileadmin/redakteur/dokumente/Automotive_Radar_Dataset_for_Deep_learning_Based_3D_Object_Detection.PDF)] [[Note](ToBeFilled)]
* Deep Learning Based 3D Object Detection for Automotive Radar and Camera  [[Paper](https://www.astyx.com/fileadmin/redakteur/dokumente/Deep_Learning_Based_3D_Object_Detection_for_Automotive_Radar_and_Camera.PDF)] [[Note](ToBeFilled)]
* Learn to Combine Modalities in Multimodal Deep Learning  [[Paper](https://arxiv.org/pdf/1805.11730.pdf)] [[Note](ToBeFilled)]

