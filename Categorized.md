This is a categorized summary of the notes by the engineering fields.


### Transformer
* Perceiver: General Perception with Iterative Attention][[Note](papers/Perceiver.md)] <kbd>Deepmind</kbd>  `Transformer`
* Perceiver IO: A General Architecture for Structured Inputs & Outputs][[Note](papers/Perceiver.md)] <kbd>Deepmind</kbd>  `Transformer`


### Production
* Hidden Technical Debt in Machine Learning Systems [[Note](papers/MLStack.md)] <kbd>NeurIPS 15</kbd>  `Production`
* The ML Test Score: A Rubric for ML Production Readiness and Technical Debt Reduction [[Note](papers/MLStack.md)] <kbd>IEEE BigData 17</kbd>  `Production`


### General-DL
* Object Detection as a Machine Learning Problem [[Note](lectures/rethink_OD_girshick.md)] <kbd>ECCVW 20</kbd>  `OD`
* Geoffrey Hinton and Yann LeCun to Deliver Turing Lecture  [[Link](https://www.youtube.com/watch?v=VsnQf7exv5I)] [[Note](https://github.com/xudong19/DeepLearningNotes/blob/master/notes/turing_lecture_2018.md)] <kbd>ACM Turing Lecture19</kbd>


### Planning
* A Survey of Motion Planning and Control Techniques for Self-driving Urban Vehicles [[Note]] <kbd>IEEE T-IV 16</kbd>  `Planning`
* End-To-End Interpretable Neural Motion Planner [[Note]] <kbd>CVPR 19</kbd>  `Planning`
* Hierarchical Reinforcement Learning for Self-Driving Decision-Making without Reliance on Labeled Driving Data [[Note]] <kbd>IET ITS 20</kbd>  `Planning`
* Perceive, Predict, and Plan: Safe Motion Planning Through Interpretable Semantic Representations [[Note]] <kbd>ECCV 20</kbd>  `Planning`


### Semi-supervised
* Self-Training With Noisy Student Improves ImageNet Classification [[Note](papers/noisestudent.md)] <kbd>CVPR 20</kbd>  `Semi-supervised`
* Data Distillation: Towards Omni-Supervised Learning [[Note](papers/DataDistillationFAIR.md)] <kbd>CVPR 18</kbd>  `Semi-supervised`


### Object Detection
* Generalized Focal Loss: Learning Qualified and Distributed Bounding Boxes for Dense Object Detection [[Note](papers/GFocal.md)] <kbd>NeurIPS 20</kbd>  `OD`
* TIDE: A General Toolbox for Identifying Object Detection Errors [[Note](papers/tide.md)] <kbd>ECCV 20</kbd>  `OD`
* Bridging the Gap Between Anchor-based and Anchor-free Detection via Adaptive Training Sample Selection [[Note](papers/ATSS.md)] <kbd>CVPR 20</kbd>  `OD`
* FCOS: Fully Convolutional One-Stage Object Detection [[Note](papers/FCOS.md)] <kbd>ICCV 19</kbd>  `OD`
* OneNet: Towards End-to-End One-Stage Object Detection][[Note](papers/OneNet.md)] <kbd>arXiv 20</kbd>  `OD`
* Sparse R-CNN: End-to-End Object Detection with Learnable Proposals][[Note](papers/SparseRCNN.md)] <kbd>arXiv 20</kbd>  `OD`
* End-to-End Object Detection with Fully Convolutional Network][[Note](papers/DeFCN.md)] <kbd>arXiv 20</kbd>  `OD`

### Monocular 3D
* Center3D: Center-based Monocular 3D Object Detection with Joint Depth Understanding][[Note](papers/Center3D.md)] <kbd>arXiv 20</kbd>  `Mono3D`


### MonoDepth and Visual Odometry
* Visual Odometry Revisited: What Should Be Learnt?][[Note](papers/DF-VO.md)] <kbd>ICRA 20</kbd>  `VO`


### Instance Segmentation
* SOLO: Segmenting Objects by Locations][[Note](papers/SOLO.md)] <kbd>ECCV 20</kbd>  `IS`
* SOLOv2: Dynamic, Faster and Stronger][[Note](papers/SOLO.md)] <kbd>NeurIPS 20</kbd>  `IS`
* YOLACT++: Better Real-time Instance Segmentation [[Note](papers/YOLACT.md)] <kbd>PAML 20</kbd>  `IS`
* YOLACT: Real-time Instance Segmentation [[Note](papers/YOLACT.md)] <kbd>ICCV 19</kbd>  `IS`


### Tracking
* SoDA: Multi-Object Tracking with Soft Data Association [[Note](papers/SoDA.md)] <kbd>arXiv 20</kbd>  `MOT`
* How To Train Your Deep Multi-Object Tracker [[Note](papers/DeepMOT.md)] <kbd>CVPR 20</kbd>  `MOT`
* Tracking Objects as Points [[Note](papers/CenterTrack.md)] <kbd>ECCV 20?</kbd>  `MOT`
* Simple Online and Realtime Tracking with a Deep Association Metric [[Note](papers/sort.md)] <kbd>ICIP 17</kbd>  `MOT`
* Towards Real-Time Multi-Object Tracking [[Note](papers/Towards-Realtime-MOT.md)] <kbd>ECCV 20?</kbd>  `MOT`
* GNN3DMOT: Graph Neural Network for 3D Multi-Object Tracking with Multi-Feature Learning [[Note](papers/GNN3DMOT.md)] <kbd>CVPR 20</kbd>  `MOT`
* SQE: a Self Quality Evaluation Metric for Parameters Optimization in Multi-Object Tracking [[Note](papers/SQE.md)] <kbd>CVPR 20</kbd>  `MOT`
* RetinaTrack: Online Single Stage Joint Detection and Tracking [[Note](papers/RetinaTrack.md)] <kbd>CVPR 20</kbd>  `MOT`
* A Simple Baseline for Multi-Object Tracking [[Note](papers/FairMOT.md)] <kbd>ECCV 20?</kbd>  `MOT`

### Point Clouds
* Center-based 3D Object Detection and Tracking][[Note](papers/centerpoint.md)] <kbd>CVPR 20</kbd>  `PC`
* 3DSSD: Point-based 3D Single Stage Object Detector][[Note](papers/3DSSD.md)] <kbd>CVPR 20</kbd>  `PC`
* PointRCNN: 3D Object Proposal Generation and Detection from Point Cloud][[Note](papers/PointRCNN.md)] <kbd>CVPR 19</kbd>  `PC`
* PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation  [[Paper](https://arxiv.org/abs/1612.00593)] [[Note](https://github.com/xudong19/DeepLearningNotes/blob/master/papers/PointNet_2017.md)] [CVPR2018]


### Pedestrain
* Itâ€™s Not All About Size: On the Role of Data Properties in Pedestrian Detection [[Note](papers/Its_Not_All_About_Size_On_the_Role_of_Data.md)] <kbd>ECCVW 18</kbd>  `Pedestrian`
* MonoLoco: Monocular 3D Pedestrian Localization and Uncertainty Estimation [[Note](papers/Monoloco.md)] <kbd>ICCV 19</kbd>  `Pedestrian`
* MEBOW: Monocular Estimation of Body Orientation In the Wild [[Note](papers/MEBOW.md)] <kbd>CVPR 20</kbd>  `Pedestrian`
* CrowdHuman: A Benchmark for Detecting Human in a Crowd [[Note](papers/CrowdHuman.md)] <kbd>ArXiv 18</kbd>  `Pedestrian`
* In Defense of the Classification Loss for Person Re-Identification [[Note](papers/cls-reid.md)] <kbd>CVPR 19</kbd>  `Pedestrian`

<br/> 

### Compressing Networks

* MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications  [[Paper](https://arxiv.org/abs/1704.04861)] [[Note](https://github.com/xudong19/DeepLearningNotes/blob/master/papers/MobileNets_series.md#mobilenets-efficient-convolutional-neural-networks-for-mobile-vision-applications)]
* MobileNetV2: Inverted Residuals and Linear Bottlenecks  [[Paper](https://arxiv.org/abs/1801.04381)] [[Note](https://github.com/xudong19/DeepLearningNotes/blob/master/papers/MobileNets_series.md#mobilenetv2-inverted-residuals-and-linear-bottlenecks)]
* Searching for MobileNetV3  [[Paper](https://arxiv.org/abs/1905.02244)] [[Note](https://github.com/xudong19/DeepLearningNotes/blob/master/papers/MobileNets_series.md#searching-for-mobilenetv3)]
* SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB model size  [[Paper](https://arxiv.org/abs/1602.07360)] [[Note](https://github.com/xudong19/DeepLearningNotes/blob/master/papers/squeezenet.md)]
* NetAdapt: Platform-Aware Neural Network Adaptation for Mobile Applications  [[Paper](https://arxiv.org/abs/1804.03230)] [[Note](https://github.com/xudong19/DeepLearningNotes/blob/master/papers/NetAdapt.md)]
* MnasNet: Platform-Aware Neural Architecture Search for Mobile  [[Paper](https://arxiv.org/abs/1807.11626)] [[Note](https://github.com/xudong19/DeepLearningNotes/blob/master/papers/MnasNet.md)]
* EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks  [[Paper](https://arxiv.org/abs/1905.11946)] [[Note](https://github.com/xudong19/DeepLearningNotes/blob/master/papers/EfficientNet.md)]
* Exploiting Kernel Sparsity and Entropy for Interpretable CNN Compression  [[Paper](https://arxiv.org/abs/1812.04368)] [[Note](https://github.com/xudong19/DeepLearningNotes/blob/master/papers/KSE.md)]
* LeGR: Filter Pruning via Learned Global Ranking  [[Paper](https://arxiv.org/abs/1904.12368)] [[Note](./papers/LeGR.md)]


<br/> 

### Action Recognition from Videos

* An Attention-based Recurrent Convolutional Network for Vehicle Taillight Recognition  [[Paper](https://arxiv.org/abs/1906.03683)] [[Note](https://github.com/xudong19/DeepLearningNotes/blob/master/papers/AttenRCN.md)] <kbd>IV19</kbd>
* DeepSignals: Predicting Intent of Drivers Through Visual Signals  [[Paper](https://arxiv.org/abs/1905.01333)] [[Note](https://github.com/xudong19/DeepLearningNotes/blob/master/papers/DeepSignals.md)] <kbd>ICRA19</kbd>
* VideoLSTM Convolves, Attends and Flows for Action Recognition  [[Paper](https://www.sciencedirect.com/science/article/pii/S1077314217301741)] [[Note](https://github.com/xudong19/DeepLearningNotes/blob/master/papers/VideoLSTM.md)] <kbd>CVIU18</kbd>


<br/> 

### Radar and Camera Fusion

* Automotive Radar Dataset for Deep Learning Based 3D Object Detection  [[Paper](https://www.astyx.com/fileadmin/redakteur/dokumente/Automotive_Radar_Dataset_for_Deep_learning_Based_3D_Object_Detection.PDF)] [[Note](ToBeFilled)]
* Deep Learning Based 3D Object Detection for Automotive Radar and Camera  [[Paper](https://www.astyx.com/fileadmin/redakteur/dokumente/Deep_Learning_Based_3D_Object_Detection_for_Automotive_Radar_and_Camera.PDF)] [[Note](ToBeFilled)]
* Learn to Combine Modalities in Multimodal Deep Learning  [[Paper](https://arxiv.org/pdf/1805.11730.pdf)] [[Note](ToBeFilled)]



