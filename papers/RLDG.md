[RLDG: Robotic Generalist Policy Distillation via Reinforcement Learning](https://arxiv.org/pdf/2412.09858) [RSS25]
---------------	

__TL;DR__: blablablablabla

__keywords__: bla-bla

__Resources__: [[Github](blabla)] 

__Other Notable Info__: [Project Page](https://generalist-distillation.github.io/)

<br/>    

General Comments:
------
* The key insight is that train a specialized RL agent and generate task-specific data. 
* The counter-intuitive conclusion/insight is that RL generated data is better than
human-teleoperated data.
* Use data as a distillation method. Applying RL directly to foundation model can
lead to stability issues.
* The main goal is to generate a better generalist foundation model

Key ideas and technical details:
------
* 
* 

Other noteworthy points:
------
* 
* 

Screenshots:
------
<!-- ![Image1](../img/pointnet_net.png "Architecture") -->

